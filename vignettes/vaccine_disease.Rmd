---
title: "Vaccines and Infectious Disease"
author: Aris Paschalidis
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vaccines and Infectious Disease}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(CAvaccines)
library(ggplot2)
```

# Read in Data
The first step in any analysis we want to perform is to first read in our datasets.
For this analysis, we will utilize two datasets, both found in the Data/ folder
of this project: county_vaccination, and pertussis. Both of these of these datasets
are documented in the associated help files, but we summarize here for convenience.
Before continuing with this vignette, we strongly encourage readers to examine the
documentation for each dataset, if they have not already.

* `county_vaccination` is a dataset containing information about vaccination rates
for each CA county for the years of 2008-2017.
* `pertussis` is a dataset containing all pertussis cases, arranged by county, from
the years of 2008-2017 in the state of California.

One approach to examining our data is to study the variable names. 

```{r}
# We print the names of each dataset
names(county_vaccination)
names(pertussis)
```

Another, likely more useful option, is to visualize our data. To do this, we 
will create plots of our variables. We first start by creating maps of CA counties
and shading the counties according to a specific measurement. The following set
of graphs shows the percent of students with DTP vaccinations, the percent
of students that are up to date on their vaccinations, the percent of students
that have a PME, and the percent of students that have a PBE.

```{r}
# Graphs are for the year 2017
to_map <- dplyr::filter(county_vaccination, Year == "2017") %>%
  dplyr::select(Jurisdiction, percent_DTP, percent_Up_to_Date, percent_PME, percent_PBE) %>%
  dplyr::mutate_at(dplyr::vars(dplyr::contains("percent_")), ~.*100)

map_plot(to_map, "percent_DTP", "Total DTP Vaccinations")
map_plot(to_map, "percent_Up_to_Date", "Total Up to Date")
map_plot(to_map, "percent_PME", "Total PME")
map_plot(to_map, "percent_PBE", "Total PBE")
```

```{r}
omit <- na.omit(pertussis)

ggplot(omit, aes(x = Year, y = Cases)) + geom_boxplot()
ggplot(omit, aes(x = Year, y = Rates)) + geom_boxplot()

means <- as.data.frame(omit %>% dplyr::group_by(Year) %>% 
                         dplyr::summarize(avg_cases = mean(Cases), avg_rates = mean(Rates)))

ggplot(means, aes(x = Year, y = avg_cases, fill = avg_cases)) + geom_col() + theme(legend.position = "none")
ggplot(means, aes(x = Year, y = avg_rates, fill = avg_rates)) + geom_col() + theme(legend.position = "none")
```

# Modeling
We first set up data for modeling.
```{r}
`%notin%` <- Negate(`%in%`)

model_data  <- dplyr::full_join(county_vaccination, pertussis, by = c("Jurisdiction", "Year")) %>% 
  dplyr::filter(Year %notin% c("2010")) %>%
  dplyr::filter(Jurisdiction != "totals")

summary(model_data)
```

By total numbers and cases.
```{r}
scaled_total_data <- model_data %>% 
  dplyr::select(-one_of(c("Jurisdiction", "Year", "Rates"))) %>%
  dplyr::select(-contains("percent_")) %>%
  dplyr::mutate_if(is.numeric, scale) %>% 
  as.data.frame() %>% na.omit()

# fit <- forecast::tslm(Cases ~ total_Up_to_Date+total_Conditional+total_PME+total_PBE+total_DTP+total_Polio+total_MMR+total_HepB+total_Var+trend, data=ts(scaled_total_data))
# summary(fit)

# set.seed(0)
t_sample = caTools::sample.split(scaled_total_data$Cases, SplitRatio = 0.7)
t_train = subset(scaled_total_data, t_sample == TRUE)
t_test  = subset(scaled_total_data, t_sample == FALSE)

lm <- stats::lm(Cases ~., data = t_train)
summary(lm)

predict_lm <- lm %>% stats::predict(t_test)
print(paste("Test R2 Linear:", round(caret::R2(predict_lm, t_test$Cases), 4)))

cart <- rpart::rpart(Cases ~., data = t_train)
# prune_cart <- rpart::prune(cart, cp = cart$cptable[which.min(cart$cptable[,"xerror"]),"CP"])

predict_cart <- cart %>% stats::predict(t_test)
confMat <- table(t_test$Cases, predict_cart)
print(paste("Test Accuracy CART:", round(sum(diag(confMat))/sum(confMat), 4)))
```

By percents and rates
```{r}
scaled_percent_data <- model_data %>% 
  dplyr::select(-one_of(c("Jurisdiction", "Year", "Cases"))) %>%
  dplyr::select(-contains("total_")) %>%
  # dplyr::mutate_if(is.numeric, scale) %>%
  as.data.frame() %>% na.omit()

# scaled_percent_data$Rates <- scaled_percent_data$Rates/1000
summary(scaled_percent_data)

# set.seed(0)
p_sample = caTools::sample.split(scaled_percent_data$Rates, SplitRatio = 0.8)
p_train = subset(scaled_percent_data, p_sample == TRUE)
p_test  = subset(scaled_percent_data, p_sample == FALSE)

lm <- stats::lm(Rates ~., data = p_train)
summary(lm)

predict_lm <- lm %>% stats::predict(p_test)
print(paste("Test R2 Linear:", round(caret::R2(predict_lm, p_test$Rates), 4)))

cart <- rpart::rpart(Rates ~., data = p_train)
# prune_cart <- rpart::prune(cart, cp = cart$cptable[which.min(cart$cptable[,"xerror"]),"CP"])

predict_cart <- cart %>% stats::predict(p_test)
confMat <- table(p_test$Rates, predict_cart)
print(paste("Test Accuracy CART:", round(sum(diag(confMat))/sum(confMat), 4)))
```


```{r}
corr_mat <- Hmisc::rcorr(as.matrix(scaled_total_data), type = "spearman")
M <- corr_mat$r
P_mat <- corr_mat$P

corrplot::corrplot(M, method = "color", col = RColorBrewer::brewer.pal(n=8, name="PuBu"),
  addCoef.col = "black",
  tl.col = "black", tl.srt = 50,tl.cex = 0.60,
  p.mat = P_mat, sig.level = 0.05, pch.cex = 5,
  mar=c(0,0,2,0), number.cex = 1)
```



